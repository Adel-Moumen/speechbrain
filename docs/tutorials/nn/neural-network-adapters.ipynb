{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82d21c0-4bdb-4caf-af73-30d0f43ecbab",
   "metadata": {},
   "source": [
    "# Neural Network Adapters for faster low-memory fine-tuning\n",
    "\n",
    "This tutorial covers the SpeechBrain implementation of adapters such as LoRA. This includes how to integrate either SpeechBrain implemented adapters, custom adapters, and adapters from libraries such as PEFT into a pre-trained model.\n",
    "\n",
    "## Prerequisite\n",
    "- [Speech Recognition From Scratch](https://speechbrain.readthedocs.io/en/latest/tutorials/tasks/speech-recognition-from-scratch.html)\n",
    "\n",
    "## Introduction and Background\n",
    "\n",
    "As pre-trained models become larger and more capable, there is growing interest in methods for adapting them for specific tasks in a memory-efficient way, within a reasonable time span. One such technique is freezing the original parameters and inserting a small number of additional parameters into the original model, which are called \"adapters.\" These adapters can often match the performance of full fine-tuning at a fraction of the parameter count, meaning faster and more memory-efficient fine-tuning [1]. One popular technique for doing this is known as Low-Rank Adaptation (LoRA) [2].\n",
    "\n",
    "On the software side, HuggingFace has produced a popular library for adapters called PEFT [3]. Our implementation includes some of the features of this library, as well as including the ability to integrate PEFT adapters into a SpeechBrain model. To explore this further, let's proceed with the installation of SpeechBrain.\n",
    "\n",
    "### Relevant bibliography\n",
    "1. N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly, \"Parameter-efficient transfer learning for NLP.\" In *International Conference on Machine Learning*, 2019.\n",
    "2. E.J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, \"LoRA: Low-rank adaptation of large language models.\" In *International Conference on Learning Representations*, 2021.\n",
    "3. S. Mangrulkar, S. Gugger, L. Debut, Y. Belkada, S. Paul, and  B. Bossan, \"PEFT: State-of-the-art parameter-efficient fine-tuning methods.\" *GitHub Repository*, 2022.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45871e4-e087-486b-af01-411603e43070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'speechbrain'...\n",
      "remote: Enumerating objects: 1693, done.\u001b[K\n",
      "remote: Counting objects: 100% (1693/1693), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1210/1210), done.\u001b[K\n",
      "remote: Total 1693 (delta 402), reused 1062 (delta 318), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (1693/1693), 23.88 MiB | 20.80 MiB/s, done.\n",
      "Resolving deltas: 100% (402/402), done.\n",
      "/home/competerscience/Documents/uvenv/bin/python: No module named pip\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/speechbrain/speechbrain.git\n",
    "!python -m pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca49a1d-5c1b-40db-b7e1-dcc8a85bcce3",
   "metadata": {},
   "source": [
    "## Simple Fine-tuning\n",
    "\n",
    "We'll first show how to use adapters on a template recipe, which includes everything necessary for full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d88fe51-301b-46d5-858e-fd47877e92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/templates/speech_recognition/ASR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/competerscience/Documents/uvenv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd speechbrain/templates/speech_recognition/ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dabda46-19ae-41b9-ab0f-6b9995b1e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/CRDNN_BPE_960h_LM/2602\n",
      "mini_librispeech_prepare - Preparation completed in previous run, skipping.\n",
      "../data/noise/data.zip exists. Skipping download\n",
      "../data/rir/data.zip exists. Skipping download\n",
      "speechbrain.utils.fetching - Fetch lm.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/lm.ckpt.\n",
      "speechbrain.utils.fetching - Fetch tokenizer.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/tokenizer.ckpt.\n",
      "speechbrain.utils.fetching - Fetch asr.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/model.ckpt.\n",
      "speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer, model\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/core.py:789: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=gradscaler_enabled)\n",
      "speechbrain.core - ASR Model Statistics:\n",
      "* Total Number of Trainable Parameters: 173.0M\n",
      "* Total Number of Parameters: 173.0M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.augment.augmenter - No augmentation is applied because the augmentation start index is greater than or equal to the number of examples in the input batch.\n",
      "100%|████████████████████████| 760/760 [09:28<00:00,  1.34it/s, train_loss=1.37]\n",
      "100%|█████████████████████████████████████████| 545/545 [01:26<00:00,  6.27it/s]\n",
      "speechbrain.utils.train_logger - epoch: 1, lr: 1.00e+00 - train loss: 1.37 - valid loss: 1.31, valid CER: 7.93, valid WER: 20.48\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/CRDNN_BPE_960h_LM/2602/save/CKPT+2024-10-01+14-39-40+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/CRDNN_BPE_960h_LM/2602/save/CKPT+2024-10-01+14-39-40+00\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/nnet/schedulers.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n",
      "100%|███████████████████████████████████████| 1310/1310 [09:27<00:00,  2.31it/s]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 1 - test loss: 1.30, test CER: 6.33, test WER: 18.13\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/CRDNN_BPE_960h_LM/2602/save/CKPT+latest\n"
     ]
    }
   ],
   "source": [
    "!python train.py train.yaml --number_of_epochs=1 --batch_size=2 --test_scorer \"!ref <valid_scorer>\" --enable_add_reverb=False --enable_add_noise=False #To speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9782e5b-5498-487f-8055-0b73f75a8ec8",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "To prove that this is working, let's just perform inference on one file. This code taken from `transcribe_file.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd9de34-e7d2-4fdd-beb7-d7ab07551c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch inference.yaml: Using existing file/symlink in /home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/templates/speech_recognition/ASR/results/CRDNN_BPE_960h_LM/2602/save/CKPT+latest/inference.yaml\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: lm, tokenizer, model, normalizer\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'THE METAL FOREST IS IN THE GREAT DOMED CAVERN THE LARGEST IN ALL OUR DOMINIANS REPLIED CALIGO ⁇ '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from speechbrain.inference.ASR import EncoderDecoderASR\n",
    "from speechbrain.utils.fetching import fetch\n",
    "\n",
    "# Ensure all the needed files end up in the same place to load with the transcriber\n",
    "save_dir = os.path.abspath(\"results/CRDNN_BPE_960h_LM/2602/save/CKPT+latest\")\n",
    "fetch(\"lm.ckpt\", \"speechbrain/asr-crdnn-rnnlm-librispeech\", save_dir)\n",
    "fetch(\"tokenizer.ckpt\", \"speechbrain/asr-crdnn-rnnlm-librispeech\", save_dir)\n",
    "fetch(\"inference.yaml\", os.getcwd(), save_dir)\n",
    "\n",
    "transcriber = EncoderDecoderASR.from_hparams(source=save_dir, hparams_file=\"inference.yaml\")\n",
    "speech_file = \"../data/LibriSpeech/dev-clean-2/1272/135031/1272-135031-0015.flac\"\n",
    "transcriber.transcribe_file(speech_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c13b9-5a32-412e-a099-951163f4ed3c",
   "metadata": {},
   "source": [
    "## Adding adapters\n",
    "\n",
    "So now that we've proved that the model is at least working, let's go ahead and add adapters. We basically need to create a new yaml file adding adapters to the model and then train with this new yaml file. To do this we'll just load the old yaml file and then we'll change all the parts necessary to train the adapted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0904742-9f03-46c4-88bb-fd7cb4326686",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.yaml\") as f:\n",
    "    train_yaml = f.read()\n",
    "\n",
    "train_yaml = train_yaml.replace(\"seed: 2602\", \"seed: 4324\")\n",
    "train_yaml = train_yaml.replace(\"output_folder: !ref results/CRDNN_BPE_960h_LM/<seed>\", \"output_folder: !ref results/crdnn_lora/<seed>\")\n",
    "train_yaml = train_yaml.replace(\"pretrained_path: speechbrain/asr-crdnn-rnnlm-librispeech\", \"pretrained_path: \" + save_dir)\n",
    "train_yaml = train_yaml.replace(\"model: !new:torch.nn.ModuleList\", \"model_pretrained: !new:torch.nn.ModuleList\")\n",
    "\n",
    "# We aren't using the LM so remove it purely for accurate parameter counts\n",
    "train_yaml = train_yaml.replace(\"\"\"\n",
    "modules:\n",
    "    encoder: !ref <encoder>\n",
    "    embedding: !ref <embedding>\n",
    "    decoder: !ref <decoder>\n",
    "    ctc_lin: !ref <ctc_lin>\n",
    "    seq_lin: !ref <seq_lin>\n",
    "    normalize: !ref <normalize>\n",
    "    lm_model: !ref <lm_model>\n",
    "\"\"\",\"\"\"\n",
    "modules:\n",
    "    encoder: !ref <encoder>\n",
    "    embedding: !ref <embedding>\n",
    "    decoder: !ref <decoder>\n",
    "    ctc_lin: !ref <ctc_lin>\n",
    "    seq_lin: !ref <seq_lin>\n",
    "    normalize: !ref <normalize>\n",
    "\"\"\")\n",
    "\n",
    "# Update load the old trained model to the `pretrained_model` object\n",
    "train_yaml = train_yaml.replace(\"\"\"\n",
    "    loadables:\n",
    "        lm: !ref <lm_model>\n",
    "        tokenizer: !ref <tokenizer>\n",
    "        model: !ref <model>\n",
    "    paths:\n",
    "        lm: !ref <pretrained_path>/lm.ckpt\n",
    "        tokenizer: !ref <pretrained_path>/tokenizer.ckpt\n",
    "        model: !ref <pretrained_path>/asr.ckpt\n",
    "\"\"\",\"\"\"\n",
    "    loadables:\n",
    "        lm: !ref <lm_model>\n",
    "        tokenizer: !ref <tokenizer>\n",
    "        model: !ref <model_pretrained>\n",
    "    paths:\n",
    "        lm: !ref <pretrained_path>/lm.ckpt\n",
    "        tokenizer: !ref <pretrained_path>/tokenizer.ckpt\n",
    "        model: !ref <pretrained_path>/model.ckpt\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# And now for adding the adapted model\n",
    "train_yaml += \"\"\"\n",
    "new_encoder: !new:speechbrain.nnet.adapters.AdaptedModel\n",
    "    model_to_adapt: !ref <encoder>\n",
    "    adapter_class: !name:speechbrain.nnet.adapters.LoRA\n",
    "    manual_adapter_insertion: True\n",
    "    adapter_kwargs:\n",
    "        rank: 8\n",
    "\n",
    "new_decoder: !new:speechbrain.nnet.adapters.AdaptedModel\n",
    "    model_to_adapt: !ref <decoder>\n",
    "    adapter_class: !name:speechbrain.nnet.adapters.LoRA\n",
    "    manual_adapter_insertion: True\n",
    "    adapter_kwargs:\n",
    "        rank: 8\n",
    "\n",
    "model: !new:torch.nn.ModuleList\n",
    "    - - !ref <new_encoder>\n",
    "      - !ref <embedding>\n",
    "      - !ref <new_decoder>\n",
    "      - !ref <ctc_lin>\n",
    "      - !ref <seq_lin>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"train_lora.yaml\", \"w\") as f:\n",
    "    f.write(train_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36508f13-7423-47eb-98dd-40274f1990b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to add two lines to the train file as well\n",
    "with open(\"train.py\") as f:\n",
    "    train_py = f.read()\n",
    "\n",
    "train_py = train_py.replace(\"\"\"\n",
    "    hparams[\"pretrainer\"].load_collected()\n",
    "\"\"\",\"\"\"\n",
    "    hparams[\"pretrainer\"].load_collected()\n",
    "    hparams[\"new_encoder\"].insert_adapters()\n",
    "    hparams[\"new_decoder\"].insert_adapters()\n",
    "\"\"\")\n",
    "\n",
    "with open(\"train_lora.py\", \"w\") as f:\n",
    "    f.write(train_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792396c-c05c-4589-b3f3-149cfd98fb34",
   "metadata": {},
   "source": [
    "## Training the adapted model\n",
    "\n",
    "Training works identically to before, using the updated lora file. The adapted model is designed to work as an in-place replacement. Notice how the number of trainable parameters is reduced to close to 1% of the original parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d088fc19-5f0b-4160-b470-0a4198f0f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.seed:Setting seed to 4324\n",
      "WARNING:speechbrain.utils.train_logger:torchvision is not available - cannot save figures\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/crdnn_lora/4324\n",
      "mini_librispeech_prepare - Preparation completed in previous run, skipping.\n",
      "../data/noise/data.zip exists. Skipping download\n",
      "../data/rir/data.zip exists. Skipping download\n",
      "speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer, model\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/core.py:793: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=gradscaler_enabled)\n",
      "speechbrain.core - ASR Model Statistics:\n",
      "* Total Number of Trainable Parameters: 1.9M\n",
      "* Total Number of Parameters: 120.1M\n",
      "* Trainable Parameters represent 1.5715% of the total size.\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/crdnn_lora/4324/save/CKPT+latest\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/nnet/schedulers.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/crdnn_lora/4324/save/CKPT+2024-10-01+16-53-38+00\n",
      "100%|███████████████████████████████████████| 1310/1310 [13:05<00:00,  1.67it/s]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 1 - test loss: 1.26, test CER: 5.98, test WER: 17.36\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/crdnn_lora/4324/save/CKPT+latest\n"
     ]
    }
   ],
   "source": [
    "!python train_lora.py train_lora.yaml --number_of_epochs=1 --batch_size=2 --test_scorer \"!ref <valid_scorer>\" --enable_add_reverb=False --enable_add_noise=False #To speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960be7a-6edb-47c1-bd8d-c7c0d486c81d",
   "metadata": {},
   "source": [
    "## Custom adapter\n",
    "\n",
    "We designed this so that you could replace the SpeechBrain adapter with a `peft` adapter:\n",
    "\n",
    "```diff\n",
    "new_encoder: !new:speechbrain.nnet.adapters.AdaptedModel\n",
    "    model_to_adapt: !ref <encoder>\n",
    "-   adapter_class: !name:speechbrain.nnet.adapters.LoRA\n",
    "+   adapter_class: !name:peft.tuners.lora.layer.Linear\n",
    "    manual_adapter_insertion: True\n",
    "    adapter_kwargs:\n",
    "-       rank: 16\n",
    "+       r: 16\n",
    "+       adapter_name: lora\n",
    "```\n",
    "\n",
    "But this trains exactly the same thing as before, so no need for us to go through the whole thing. Perhaps more interesting is designing a custom adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9682f70-489a-4a1d-b8c6-1c73d98a824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conv_lora.py\n"
     ]
    }
   ],
   "source": [
    "%%file conv_lora.py\n",
    "\n",
    "import torch\n",
    "\n",
    "class Conv2dLoRA(torch.nn.Module):\n",
    "    def __init__(self, target_module, kernel_size=3, stride=2, channels=16):\n",
    "        super().__init__()\n",
    "\n",
    "        # Disable gradient for pretrained module\n",
    "        self.pretrained_module = target_module\n",
    "        for param in self.pretrained_module.parameters():\n",
    "            param.requires_grad = False\n",
    "        device = target_module.weight.device\n",
    "\n",
    "        self.adapter_down_conv = torch.nn.Conv2D(\n",
    "            in_channels=1, out_channels=channels, padding=\"same\", stride=2, bias=False, device=device\n",
    "        )\n",
    "        self.adapter_up_scale = torch.nn.Upscale(scale_factor=2)\n",
    "        self.adapter_up_conv = torch.nn.Conv2D(\n",
    "            in_channels=channels, out_channels=1, padding=\"same\", bias=False, device=device\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Applies the LoRA Adapter.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "            Input tensor to the adapter module.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The linear outputs\n",
    "        \"\"\"\n",
    "        x_pretrained = self.pretrained_module(x)\n",
    "        x_conv_lora = self.adapter_up_conv(self.adapter_up_scale(self.adapter_down_conv(x)))\n",
    "\n",
    "        return x_pretrained + x_conv_lora * self.scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2e702a9-c07d-4a76-94bc-847b8f890579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the adapter out\n",
    "train_yaml = train_yaml.replace(\"output_folder: !ref results/crdnn_lora/<seed>\", \"output_folder: !ref results/crdnn_conv_lora/<seed>\")\n",
    "\n",
    "# We aren't using the LM so remove it purely for accurate parameter counts\n",
    "train_yaml = train_yaml.replace(\"\"\"\n",
    "modules:\n",
    "    encoder: !ref <encoder>\n",
    "    embedding: !ref <embedding>\n",
    "    decoder: !ref <decoder>\n",
    "    ctc_lin: !ref <ctc_lin>\n",
    "    seq_lin: !ref <seq_lin>\n",
    "    normalize: !ref <normalize>\n",
    "    lm_model: !ref <lm_model>\n",
    "\"\"\",\"\"\"\n",
    "modules:\n",
    "    encoder: !ref <encoder>\n",
    "    embedding: !ref <embedding>\n",
    "    decoder: !ref <decoder>\n",
    "    ctc_lin: !ref <ctc_lin>\n",
    "    seq_lin: !ref <seq_lin>\n",
    "    normalize: !ref <normalize>\n",
    "\"\"\")\n",
    "\n",
    "train_yaml.replace(\"\"\"\n",
    "    adapter_class: !name:speechbrain.nnet.adapters.LoRA\n",
    "    adapter_kwargs:\n",
    "        rank: 16\n",
    "\"\"\", \"\"\"\n",
    "    adapter_class: !name:conv_lora.Conv2dLoRA\n",
    "    adapter_kwargs:\n",
    "        kernel_size: 3\n",
    "        stride: 2\n",
    "        channels: 16\n",
    "\"\"\")\n",
    "\n",
    "with open(\"train_conv_lora.yaml\", \"w\") as f:\n",
    "    f.write(train_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56aefd64-1325-4891-a9a4-1c4e85691b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.seed:Setting seed to 4324\n",
      "WARNING:speechbrain.utils.train_logger:torchvision is not available - cannot save figures\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/crdnn_conv_lora/4324\n",
      "mini_librispeech_prepare - Preparation completed in previous run, skipping.\n",
      "../data/noise/data.zip exists. Skipping download\n",
      "../data/rir/data.zip exists. Skipping download\n",
      "speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer, model\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/core.py:793: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=gradscaler_enabled)\n",
      "speechbrain.core - ASR Model Statistics:\n",
      "* Total Number of Trainable Parameters: 1.7M\n",
      "* Total Number of Parameters: 119.9M\n",
      "* Trainable Parameters represent 1.3897% of the total size.\n",
      "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.augment.augmenter - No augmentation is applied because the augmentation start index is greater than or equal to the number of examples in the input batch.\n",
      "100%|███████████████████████| 760/760 [03:24<00:00,  3.72it/s, train_loss=0.985]\n",
      "100%|█████████████████████████████████████████| 545/545 [01:28<00:00,  6.13it/s]\n",
      "speechbrain.utils.train_logger - epoch: 1, lr: 1.00e+00 - train loss: 9.85e-01 - valid loss: 1.26, valid CER: 8.18, valid WER: 20.30\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/crdnn_conv_lora/4324/save/CKPT+2024-10-01+18-27-12+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/crdnn_conv_lora/4324/save/CKPT+2024-10-01+18-27-12+00\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/utils/checkpoints.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/nnet/schedulers.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path)\n",
      "/home/competerscience/Documents/Repositories/speechbrain/docs/tutorials/nn/speechbrain/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n",
      "100%|███████████████████████████████████████| 1310/1310 [09:31<00:00,  2.29it/s]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 1 - test loss: 1.26, test CER: 6.13, test WER: 17.52\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/crdnn_conv_lora/4324/save/CKPT+latest\n"
     ]
    }
   ],
   "source": [
    "!python train_lora.py train_conv_lora.yaml --number_of_epochs=1 --batch_size=2 --test_scorer \"!ref <valid_scorer>\" --enable_add_reverb=False --enable_add_noise=False #To speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef247c-3022-4b65-8cd0-86d01a618b79",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's it, thanks for following along! Go forth and make cool adapters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
